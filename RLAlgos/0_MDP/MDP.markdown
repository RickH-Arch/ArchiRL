- **马尔可夫性质(Markov property)**
  当且仅当某时刻的状态只取决于上一时刻的状态。
  即当前状态时未来的充分统计量，下一个状态只取决于当前状态，而不会受过去状态的影响。通过这种链式关系，历史信息得以在每个状态中被记录。

- **马尔可夫过程(Markov process)**
  指具有马尔可夫性质的随机过程，也被称为**马尔可夫链**

- **马尔可夫奖励过程(Markov reward process)**
  在马尔可夫过程基础上加入奖励函数和折扣因子，一个马尔可夫奖励过程由<S,P,r,\gamma>构成
  ![Alt text](image.png)

- **马尔可夫决策过程(Markov decision process, MDP)**
  马尔可夫过程和马尔可夫奖励过程都是自发改变的随机过程，如果有一个外界的”刺激“来共同改变这个随机过程，就有**马尔可夫决策过程**。这个外界的刺激可被称为**智能体**
___
  MDP 与 MRP 非常相像，主要区别为 MDP 中的状态转移函数和奖励函数都比 MRP 多了动作作为自变量.
  例如，一艘小船在大海中随着水流自由飘荡的过程就是一个马尔可夫奖励过程，它如果凭借运气漂到了一个目的地，就能获得比较大的奖励；如果有个水手在控制着这条船往哪个方向前进，就可以主动选择前往目的地获得比较大的奖励。
  ![Alt text](image-1.png)